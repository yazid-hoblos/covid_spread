Putting dataset into HDFS at /covid/expC
Found Hadoop streaming jar: /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar
Removing existing HDFS output path if present: /covid/expC/output
Deleted /covid/expC/output
packageJobJar: [/tmp/hadoop-unjar5763065722707667779/] [] /tmp/streamjob7939486311456720289.jar tmpDir=null
25/11/03 10:04:37 INFO impl.TimelineClientImpl: Timeline service address: http://localhost:8188/ws/v1/timeline/
25/11/03 10:04:37 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
25/11/03 10:04:37 INFO impl.TimelineClientImpl: Timeline service address: http://localhost:8188/ws/v1/timeline/
25/11/03 10:04:37 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
25/11/03 10:04:38 INFO mapred.FileInputFormat: Total input paths to process : 1
25/11/03 10:04:38 INFO mapreduce.JobSubmitter: number of splits:2
25/11/03 10:04:38 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1761895960566_0155
25/11/03 10:04:38 INFO impl.YarnClientImpl: Submitted application application_1761895960566_0155
25/11/03 10:04:38 INFO mapreduce.Job: The url to track the job: http://f68875b3927a:8088/proxy/application_1761895960566_0155/
25/11/03 10:04:38 INFO mapreduce.Job: Running job: job_1761895960566_0155
25/11/03 10:04:42 INFO mapreduce.Job: Job job_1761895960566_0155 running in uber mode : false
25/11/03 10:04:42 INFO mapreduce.Job:  map 0% reduce 0%
25/11/03 10:04:48 INFO mapreduce.Job:  map 100% reduce 0%
25/11/03 10:04:52 INFO mapreduce.Job:  map 100% reduce 100%
25/11/03 10:04:53 INFO mapreduce.Job: Job job_1761895960566_0155 completed successfully
25/11/03 10:04:54 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=24864709
		FILE: Number of bytes written=50093479
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=21540122
		HDFS: Number of bytes written=1985606
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=7751
		Total time spent by all reduces in occupied slots (ms)=2467
		Total time spent by all map tasks (ms)=7751
		Total time spent by all reduce tasks (ms)=2467
		Total vcore-milliseconds taken by all map tasks=7751
		Total vcore-milliseconds taken by all reduce tasks=2467
		Total megabyte-milliseconds taken by all map tasks=7937024
		Total megabyte-milliseconds taken by all reduce tasks=2526208
	Map-Reduce Framework
		Map input records=309501
		Map output records=928497
		Map output bytes=23007709
		Map output materialized bytes=24864715
		Input split bytes=204
		Combine input records=0
		Combine output records=0
		Reduce input groups=73424
		Reduce shuffle bytes=24864715
		Reduce input records=928497
		Reduce output records=73424
		Spilled Records=1856994
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=97
		CPU time spent (ms)=5760
		Physical memory (bytes) snapshot=743010304
		Virtual memory (bytes) snapshot=6026207232
		Total committed heap usage (bytes)=520093696
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=21539918
	File Output Format Counters 
		Bytes Written=1985606
25/11/03 10:04:54 INFO streaming.StreamJob: Output directory: /covid/expC/output
